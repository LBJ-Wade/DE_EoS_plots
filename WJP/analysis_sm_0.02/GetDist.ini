#Samlple parameter file for "GetDist" script (for processing .txt chain files from command line)

#if you are not using .paramnames file, use these lines so parameters named by number
nparam=

#Can set file_root here, or in GetDist command line as second parameter
#file_root = chains/test
KEY_FILE_ROOT
#out_root = 
KEY_OUT_ROOT
out_dir = 
#Set plot_data_dir if you want to pre-compute densities and output to files
#plot_data_dir = plot_data/

#If 0 assume 1 and no chain filename prefixes
chain_num = 8
first_chain = 5 
exclude_chain = 

#If generated chain at higher temperature can cool for computing results
cool = 1

#For disgarding burn-in if using raw chains
#if < 1 interpreted as a fraction of the total number of rows (0.3 ignores first 30% of lines)
#(ignored when parameter grid or chain .properties.ini settings are explicitly set)
ignore_rows = 0

#Confidence limits for marginalized constraints.
#Also used for 2D plots, but only number set by plot settings actually shown
contours = 0.68 0.95 0.99

#If the distribution is skewed, so two probability of tails differs by more 
#than credible_interval_threshold of the peak value, use equal-probability limits 
#rather than integrating inwards equally at both tails.
#Note credible interval depends on density estimation parameters
credible_interval_threshold = 0.05

#Determine bounds from projected ND confidence range for contours[ND_contour_range]
#If -1 use bounds determined entirely from 1D marginalized densities
#Use 0 or 1 if 2D plot contours are hitting edges
range_ND_contour = -1

#1D marginalized confidence limit to use to determine parameter ranges
range_confidence = 0.001

#Confidence limit to use for convergence tests (splits and Raftery Lewis)
converge_test_limit = 0.95

#Sample binning for 1D plots
fine_bins = 1024

#if -1: set optimized smoothing bandwidth automatically for each parameter
#if >= 1: smooth by smooth_scale_1D bin widths
#if > 0  and <1: smooth by Gaussian of smooth_scale_1D standard deviations in each parameter
#                (around 0.2-0.5 is often good)
#if < 0: automatic, with the overall smoothing length scaled by abs(smooth_scale_1D) from default
smooth_scale_1D =-1

#0 is basic normalization correction
#1 is linear boundary kernel (should get gradient correct)
#2 is a higher order kernel, that also affects estimates way from the boundary (1D only)
boundary_correction_order=1

#Correct for (over-smoothing) biases using multiplicative bias correction
#i.e. by interating estimates using the re-weighted 'flattened' bins
#Note that automatic bandwidth accounts for this by increasing the smoothing scale
#as mult_bias_correction_order increases (may not converge for large values).
mult_bias_correction_order = 1

#if -1: automatic optimized bandwidth matrix selection
#if >= 1: smooth by smooth_scale_2D bin widths
#if > 0  and <1: smooth by Gaussian of smooth_scale_2D standard deviations in each parameter
#                (around 0.3-0.7 is often good)
#if < 0: automatic, with the overall smoothing length scaled by abs(smooth_scale_2D) from default
smooth_scale_2D = -1

#maximum correlation ellipticity to allow for 2D kernels. Set to 0 to force non-elliptical.
max_corr_2D = 0.99

#sample binning in each direction for 2D plotting
fine_bins_2D = 256

#maximum number of points for 3D plots
max_scatter_points = 2000

#output bins for 1D plotting (only for GetDist.py output to files, or scale if smooth_scale_2D>1) 
num_bins = 100

#output bins for 2D plotting (not used, just scale if smooth_scale_2D>1) 
num_bins_2D=40



#set no_tests=T not to compute or output convergence statistics 
no_tests = F

#Default chain files have columns: weight, -log(like), param1, param2, ...
#samples_are_chains = F can be used if instead the first two columns not present (assumed to be 1 and 0)
samples_are_chains = T

#settings for output of plot files

#No plot files produced if no_plots = F
no_plots = T

plot_meanlikes = F
shade_meanlikes = F

#if we only want all 2D plots agains a particular given parameter name
plot_2D_param = 

#if above not set, instead plot just these combinations:
#if both zero it will plot most correlated variables
plot_2D_num = 0
plot1 = param1 param2
plot2 =

#number of sample scatter (3D) plots, colored by third parameter
#if last parameter is 0 or -1 colored by the parameter most correlated
#with one of the eigenvector directions (e.g. parallel or orthogonal to degeneracy)
num_3D_plots = 0
3D_plot1 = param1 param2 param3

#Output 2D plots for param combos with 1D marginalized plots along the diagonal
triangle_plot = T

triangle_plot_filled = T
#Uses all parameters unless triangle_params is set
triangle_params = 

#Parameters to use. If not specified use all parameters which have labels.
#plot_params = param1 param2 param3

#Output ND posteriors for selected parameters
dump_ND_bins = F
num_bins_ND = 10
ND_params = param1 param2 param3 param4


#If need to give limits on derived parameters if prior cuts off distribution where not very small
#For most parameters these are handled automatically from the input chain .ranges file
#limits[myparam]= 0 N

#compute two-tail marginalized limits irrespective of limits settings above and .ranges
#(otherwise limits are two-tail only if not near boundary)
force_twotail = F

#PCA - analysis output in file file_root.PCA
#number of parameter to do PCA for
PCA_num = 0
PCA_normparam = 1
#The parameters to use
PCA_params = 1 2 3
#L for log(x), M for log(-x), N for no log
PCA_func   = LLL

#if parameter_names empty set from file_root.paramnames if it exists
#otherwise set up labels manually in this file using lab1=... etc.
parameter_names = par.paramnames
#params_generic.paramnames


